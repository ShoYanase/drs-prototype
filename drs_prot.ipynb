{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "drs_prot.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "OREpPvV81StC",
        "zwHRBfSebJwB"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShoYanase/drs-prototype/blob/master/drs_prot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D1MWwRJ4Fo7t",
        "colab_type": "text"
      },
      "source": [
        "# Import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EGvDGevC4XM7",
        "colab_type": "code",
        "outputId": "2cd9a2d4-d116-406a-d92e-da920db1aa44",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!apt install aptitude\n",
        "!aptitude install mecab libmecab-dev mecab-ipadic-utf8 git make curl xz-utils file -y\n",
        "!pip install mecab-python3==0.7"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  aptitude-common libcgi-fast-perl libcgi-pm-perl libclass-accessor-perl\n",
            "  libcwidget3v5 libencode-locale-perl libfcgi-perl libhtml-parser-perl\n",
            "  libhtml-tagset-perl libhttp-date-perl libhttp-message-perl libio-html-perl\n",
            "  libio-string-perl liblwp-mediatypes-perl libparse-debianchangelog-perl\n",
            "  libsigc++-2.0-0v5 libsub-name-perl libtimedate-perl liburi-perl libxapian30\n",
            "Suggested packages:\n",
            "  aptitude-doc-en | aptitude-doc apt-xapian-index debtags tasksel\n",
            "  libcwidget-dev libdata-dump-perl libhtml-template-perl libxml-simple-perl\n",
            "  libwww-perl xapian-tools\n",
            "The following NEW packages will be installed:\n",
            "  aptitude aptitude-common libcgi-fast-perl libcgi-pm-perl\n",
            "  libclass-accessor-perl libcwidget3v5 libencode-locale-perl libfcgi-perl\n",
            "  libhtml-parser-perl libhtml-tagset-perl libhttp-date-perl\n",
            "  libhttp-message-perl libio-html-perl libio-string-perl\n",
            "  liblwp-mediatypes-perl libparse-debianchangelog-perl libsigc++-2.0-0v5\n",
            "  libsub-name-perl libtimedate-perl liburi-perl libxapian30\n",
            "0 upgraded, 21 newly installed, 0 to remove and 25 not upgraded.\n",
            "Need to get 3,877 kB of archives.\n",
            "After this operation, 15.6 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 aptitude-common all 0.8.10-6ubuntu1 [1,014 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/main amd64 libsigc++-2.0-0v5 amd64 2.10.0-2 [10.9 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/main amd64 libcwidget3v5 amd64 0.5.17-7 [286 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libxapian30 amd64 1.4.5-1ubuntu0.1 [631 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu bionic/main amd64 aptitude amd64 0.8.10-6ubuntu1 [1,269 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu bionic/main amd64 libhtml-tagset-perl all 3.20-3 [12.1 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu bionic/main amd64 liburi-perl all 1.73-1 [77.2 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic/main amd64 libhtml-parser-perl amd64 3.72-3build1 [85.9 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic/main amd64 libcgi-pm-perl all 4.38-1 [185 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu bionic/main amd64 libfcgi-perl amd64 0.78-2build1 [32.8 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu bionic/main amd64 libcgi-fast-perl all 1:2.13-1 [9,940 B]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu bionic/main amd64 libsub-name-perl amd64 0.21-1build1 [11.6 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu bionic/main amd64 libclass-accessor-perl all 0.51-1 [21.2 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu bionic/main amd64 libencode-locale-perl all 1.05-1 [12.3 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu bionic/main amd64 libtimedate-perl all 2.3000-2 [37.5 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu bionic/main amd64 libhttp-date-perl all 6.02-1 [10.4 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu bionic/main amd64 libio-html-perl all 1.001-1 [14.9 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu bionic/main amd64 liblwp-mediatypes-perl all 6.02-1 [21.7 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu bionic/main amd64 libhttp-message-perl all 6.14-1 [72.1 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu bionic/main amd64 libio-string-perl all 1.08-3 [11.1 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu bionic/main amd64 libparse-debianchangelog-perl all 1.2.0-12 [49.5 kB]\n",
            "Fetched 3,877 kB in 1s (3,531 kB/s)\n",
            "Selecting previously unselected package aptitude-common.\n",
            "(Reading database ... 133872 files and directories currently installed.)\n",
            "Preparing to unpack .../00-aptitude-common_0.8.10-6ubuntu1_all.deb ...\n",
            "Unpacking aptitude-common (0.8.10-6ubuntu1) ...\n",
            "Selecting previously unselected package libsigc++-2.0-0v5:amd64.\n",
            "Preparing to unpack .../01-libsigc++-2.0-0v5_2.10.0-2_amd64.deb ...\n",
            "Unpacking libsigc++-2.0-0v5:amd64 (2.10.0-2) ...\n",
            "Selecting previously unselected package libcwidget3v5:amd64.\n",
            "Preparing to unpack .../02-libcwidget3v5_0.5.17-7_amd64.deb ...\n",
            "Unpacking libcwidget3v5:amd64 (0.5.17-7) ...\n",
            "Selecting previously unselected package libxapian30:amd64.\n",
            "Preparing to unpack .../03-libxapian30_1.4.5-1ubuntu0.1_amd64.deb ...\n",
            "Unpacking libxapian30:amd64 (1.4.5-1ubuntu0.1) ...\n",
            "Selecting previously unselected package aptitude.\n",
            "Preparing to unpack .../04-aptitude_0.8.10-6ubuntu1_amd64.deb ...\n",
            "Unpacking aptitude (0.8.10-6ubuntu1) ...\n",
            "Selecting previously unselected package libhtml-tagset-perl.\n",
            "Preparing to unpack .../05-libhtml-tagset-perl_3.20-3_all.deb ...\n",
            "Unpacking libhtml-tagset-perl (3.20-3) ...\n",
            "Selecting previously unselected package liburi-perl.\n",
            "Preparing to unpack .../06-liburi-perl_1.73-1_all.deb ...\n",
            "Unpacking liburi-perl (1.73-1) ...\n",
            "Selecting previously unselected package libhtml-parser-perl.\n",
            "Preparing to unpack .../07-libhtml-parser-perl_3.72-3build1_amd64.deb ...\n",
            "Unpacking libhtml-parser-perl (3.72-3build1) ...\n",
            "Selecting previously unselected package libcgi-pm-perl.\n",
            "Preparing to unpack .../08-libcgi-pm-perl_4.38-1_all.deb ...\n",
            "Unpacking libcgi-pm-perl (4.38-1) ...\n",
            "Selecting previously unselected package libfcgi-perl.\n",
            "Preparing to unpack .../09-libfcgi-perl_0.78-2build1_amd64.deb ...\n",
            "Unpacking libfcgi-perl (0.78-2build1) ...\n",
            "Selecting previously unselected package libcgi-fast-perl.\n",
            "Preparing to unpack .../10-libcgi-fast-perl_1%3a2.13-1_all.deb ...\n",
            "Unpacking libcgi-fast-perl (1:2.13-1) ...\n",
            "Selecting previously unselected package libsub-name-perl.\n",
            "Preparing to unpack .../11-libsub-name-perl_0.21-1build1_amd64.deb ...\n",
            "Unpacking libsub-name-perl (0.21-1build1) ...\n",
            "Selecting previously unselected package libclass-accessor-perl.\n",
            "Preparing to unpack .../12-libclass-accessor-perl_0.51-1_all.deb ...\n",
            "Unpacking libclass-accessor-perl (0.51-1) ...\n",
            "Selecting previously unselected package libencode-locale-perl.\n",
            "Preparing to unpack .../13-libencode-locale-perl_1.05-1_all.deb ...\n",
            "Unpacking libencode-locale-perl (1.05-1) ...\n",
            "Selecting previously unselected package libtimedate-perl.\n",
            "Preparing to unpack .../14-libtimedate-perl_2.3000-2_all.deb ...\n",
            "Unpacking libtimedate-perl (2.3000-2) ...\n",
            "Selecting previously unselected package libhttp-date-perl.\n",
            "Preparing to unpack .../15-libhttp-date-perl_6.02-1_all.deb ...\n",
            "Unpacking libhttp-date-perl (6.02-1) ...\n",
            "Selecting previously unselected package libio-html-perl.\n",
            "Preparing to unpack .../16-libio-html-perl_1.001-1_all.deb ...\n",
            "Unpacking libio-html-perl (1.001-1) ...\n",
            "Selecting previously unselected package liblwp-mediatypes-perl.\n",
            "Preparing to unpack .../17-liblwp-mediatypes-perl_6.02-1_all.deb ...\n",
            "Unpacking liblwp-mediatypes-perl (6.02-1) ...\n",
            "Selecting previously unselected package libhttp-message-perl.\n",
            "Preparing to unpack .../18-libhttp-message-perl_6.14-1_all.deb ...\n",
            "Unpacking libhttp-message-perl (6.14-1) ...\n",
            "Selecting previously unselected package libio-string-perl.\n",
            "Preparing to unpack .../19-libio-string-perl_1.08-3_all.deb ...\n",
            "Unpacking libio-string-perl (1.08-3) ...\n",
            "Selecting previously unselected package libparse-debianchangelog-perl.\n",
            "Preparing to unpack .../20-libparse-debianchangelog-perl_1.2.0-12_all.deb ...\n",
            "Unpacking libparse-debianchangelog-perl (1.2.0-12) ...\n",
            "Setting up libhtml-tagset-perl (3.20-3) ...\n",
            "Setting up libxapian30:amd64 (1.4.5-1ubuntu0.1) ...\n",
            "Setting up libencode-locale-perl (1.05-1) ...\n",
            "Setting up libtimedate-perl (2.3000-2) ...\n",
            "Setting up libio-html-perl (1.001-1) ...\n",
            "Setting up aptitude-common (0.8.10-6ubuntu1) ...\n",
            "Setting up liblwp-mediatypes-perl (6.02-1) ...\n",
            "Setting up liburi-perl (1.73-1) ...\n",
            "Setting up libhtml-parser-perl (3.72-3build1) ...\n",
            "Setting up libcgi-pm-perl (4.38-1) ...\n",
            "Setting up libio-string-perl (1.08-3) ...\n",
            "Setting up libsub-name-perl (0.21-1build1) ...\n",
            "Setting up libfcgi-perl (0.78-2build1) ...\n",
            "Setting up libsigc++-2.0-0v5:amd64 (2.10.0-2) ...\n",
            "Setting up libclass-accessor-perl (0.51-1) ...\n",
            "Setting up libhttp-date-perl (6.02-1) ...\n",
            "Setting up libcgi-fast-perl (1:2.13-1) ...\n",
            "Setting up libparse-debianchangelog-perl (1.2.0-12) ...\n",
            "Setting up libhttp-message-perl (6.14-1) ...\n",
            "Setting up libcwidget3v5:amd64 (0.5.17-7) ...\n",
            "Setting up aptitude (0.8.10-6ubuntu1) ...\n",
            "update-alternatives: using /usr/bin/aptitude-curses to provide /usr/bin/aptitude (aptitude) in auto mode\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.6/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n",
            "git is already installed at the requested version (1:2.17.1-1ubuntu0.5)\n",
            "make is already installed at the requested version (4.1-9.1ubuntu1)\n",
            "curl is already installed at the requested version (7.58.0-2ubuntu3.8)\n",
            "xz-utils is already installed at the requested version (5.2.2-1.3)\n",
            "git is already installed at the requested version (1:2.17.1-1ubuntu0.5)\n",
            "make is already installed at the requested version (4.1-9.1ubuntu1)\n",
            "curl is already installed at the requested version (7.58.0-2ubuntu3.8)\n",
            "xz-utils is already installed at the requested version (5.2.2-1.3)\n",
            "The following NEW packages will be installed:\n",
            "  file libmagic-mgc{a} libmagic1{a} libmecab-dev libmecab2{a} mecab mecab-ipadic{a} mecab-ipadic-utf8 mecab-jumandic{a} mecab-jumandic-utf8{a} mecab-utils{a} \n",
            "0 packages upgraded, 11 newly installed, 0 to remove and 25 not upgraded.\n",
            "Need to get 29.3 MB of archives. After unpacking 282 MB will be used.\n",
            "Get: 1 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libmagic-mgc amd64 1:5.32-2ubuntu0.3 [184 kB]\n",
            "Get: 2 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libmagic1 amd64 1:5.32-2ubuntu0.3 [68.7 kB]\n",
            "Get: 3 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 file amd64 1:5.32-2ubuntu0.3 [22.1 kB]\n",
            "Get: 4 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libmecab2 amd64 0.996-5 [257 kB]\n",
            "Get: 5 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libmecab-dev amd64 0.996-5 [308 kB]\n",
            "Get: 6 http://archive.ubuntu.com/ubuntu bionic/universe amd64 mecab-utils amd64 0.996-5 [4,856 B]\n",
            "Get: 7 http://archive.ubuntu.com/ubuntu bionic/universe amd64 mecab-jumandic-utf8 all 7.0-20130310-4 [16.2 MB]\n",
            "Get: 8 http://archive.ubuntu.com/ubuntu bionic/universe amd64 mecab-jumandic all 7.0-20130310-4 [2,212 B]\n",
            "Get: 9 http://archive.ubuntu.com/ubuntu bionic/universe amd64 mecab-ipadic all 2.7.0-20070801+main-1 [12.1 MB]\n",
            "Get: 10 http://archive.ubuntu.com/ubuntu bionic/universe amd64 mecab amd64 0.996-5 [132 kB]\n",
            "Get: 11 http://archive.ubuntu.com/ubuntu bionic/universe amd64 mecab-ipadic-utf8 all 2.7.0-20070801+main-1 [3,522 B]\n",
            "Fetched 29.3 MB in 2s (16.5 MB/s)\n",
            "Selecting previously unselected package libmagic-mgc.\n",
            "(Reading database ... 134331 files and directories currently installed.)\n",
            "Preparing to unpack .../00-libmagic-mgc_1%3a5.32-2ubuntu0.3_amd64.deb ...\n",
            "Unpacking libmagic-mgc (1:5.32-2ubuntu0.3) ...\n",
            "Selecting previously unselected package libmagic1:amd64.\n",
            "Preparing to unpack .../01-libmagic1_1%3a5.32-2ubuntu0.3_amd64.deb ...\n",
            "Unpacking libmagic1:amd64 (1:5.32-2ubuntu0.3) ...\n",
            "Selecting previously unselected package file.\n",
            "Preparing to unpack .../02-file_1%3a5.32-2ubuntu0.3_amd64.deb ...\n",
            "Unpacking file (1:5.32-2ubuntu0.3) ...\n",
            "Selecting previously unselected package libmecab2:amd64.\n",
            "Preparing to unpack .../03-libmecab2_0.996-5_amd64.deb ...\n",
            "Unpacking libmecab2:amd64 (0.996-5) ...\n",
            "Selecting previously unselected package libmecab-dev.\n",
            "Preparing to unpack .../04-libmecab-dev_0.996-5_amd64.deb ...\n",
            "Unpacking libmecab-dev (0.996-5) ...\n",
            "Selecting previously unselected package mecab-utils.\n",
            "Preparing to unpack .../05-mecab-utils_0.996-5_amd64.deb ...\n",
            "Unpacking mecab-utils (0.996-5) ...\n",
            "Selecting previously unselected package mecab-jumandic-utf8.\n",
            "Preparing to unpack .../06-mecab-jumandic-utf8_7.0-20130310-4_all.deb ...\n",
            "Unpacking mecab-jumandic-utf8 (7.0-20130310-4) ...\n",
            "Selecting previously unselected package mecab-jumandic.\n",
            "Preparing to unpack .../07-mecab-jumandic_7.0-20130310-4_all.deb ...\n",
            "Unpacking mecab-jumandic (7.0-20130310-4) ...\n",
            "Selecting previously unselected package mecab-ipadic.\n",
            "Preparing to unpack .../08-mecab-ipadic_2.7.0-20070801+main-1_all.deb ...\n",
            "Unpacking mecab-ipadic (2.7.0-20070801+main-1) ...\n",
            "Selecting previously unselected package mecab.\n",
            "Preparing to unpack .../09-mecab_0.996-5_amd64.deb ...\n",
            "Unpacking mecab (0.996-5) ...\n",
            "Selecting previously unselected package mecab-ipadic-utf8.\n",
            "Preparing to unpack .../10-mecab-ipadic-utf8_2.7.0-20070801+main-1_all.deb ...\n",
            "Unpacking mecab-ipadic-utf8 (2.7.0-20070801+main-1) ...\n",
            "Setting up libmecab2:amd64 (0.996-5) ...\n",
            "Setting up libmagic-mgc (1:5.32-2ubuntu0.3) ...\n",
            "Setting up libmagic1:amd64 (1:5.32-2ubuntu0.3) ...\n",
            "Setting up mecab-utils (0.996-5) ...\n",
            "Setting up mecab-ipadic (2.7.0-20070801+main-1) ...\n",
            "Compiling IPA dictionary for Mecab.  This takes long time...\n",
            "reading /usr/share/mecab/dic/ipadic/unk.def ... 40\n",
            "emitting double-array: 100% |###########################################| \n",
            "/usr/share/mecab/dic/ipadic/model.def is not found. skipped.\n",
            "reading /usr/share/mecab/dic/ipadic/Suffix.csv ... 1393\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.others.csv ... 151\n",
            "reading /usr/share/mecab/dic/ipadic/Adnominal.csv ... 135\n",
            "reading /usr/share/mecab/dic/ipadic/Adverb.csv ... 3032\n",
            "reading /usr/share/mecab/dic/ipadic/Conjunction.csv ... 171\n",
            "reading /usr/share/mecab/dic/ipadic/Interjection.csv ... 252\n",
            "reading /usr/share/mecab/dic/ipadic/Auxil.csv ... 199\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.demonst.csv ... 120\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.adjv.csv ... 3328\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.number.csv ... 42\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.name.csv ... 34202\n",
            "reading /usr/share/mecab/dic/ipadic/Prefix.csv ... 221\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.nai.csv ... 42\n",
            "reading /usr/share/mecab/dic/ipadic/Verb.csv ... 130750\n",
            "reading /usr/share/mecab/dic/ipadic/Adj.csv ... 27210\n",
            "reading /usr/share/mecab/dic/ipadic/Postp.csv ... 146\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.adverbal.csv ... 795\n",
            "reading /usr/share/mecab/dic/ipadic/Filler.csv ... 19\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.proper.csv ... 27327\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.place.csv ... 72999\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.org.csv ... 16668\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.verbal.csv ... 12146\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.csv ... 60477\n",
            "reading /usr/share/mecab/dic/ipadic/Others.csv ... 2\n",
            "reading /usr/share/mecab/dic/ipadic/Symbol.csv ... 208\n",
            "reading /usr/share/mecab/dic/ipadic/Postp-col.csv ... 91\n",
            "emitting double-array: 100% |###########################################| \n",
            "reading /usr/share/mecab/dic/ipadic/matrix.def ... 1316x1316\n",
            "emitting matrix      : 100% |###########################################| \n",
            "\n",
            "done!\n",
            "update-alternatives: using /var/lib/mecab/dic/ipadic to provide /var/lib/mecab/dic/debian (mecab-dictionary) in auto mode\n",
            "Setting up libmecab-dev (0.996-5) ...\n",
            "Setting up file (1:5.32-2ubuntu0.3) ...\n",
            "Setting up mecab-jumandic-utf8 (7.0-20130310-4) ...\n",
            "Compiling Juman dictionary for Mecab.\n",
            "reading /usr/share/mecab/dic/juman/unk.def ... 37\n",
            "emitting double-array: 100% |###########################################| \n",
            "reading /usr/share/mecab/dic/juman/Suffix.csv ... 2128\n",
            "reading /usr/share/mecab/dic/juman/Special.csv ... 158\n",
            "reading /usr/share/mecab/dic/juman/ContentW.csv ... 551145\n",
            "reading /usr/share/mecab/dic/juman/AuxV.csv ... 593\n",
            "reading /usr/share/mecab/dic/juman/Assert.csv ... 34\n",
            "reading /usr/share/mecab/dic/juman/Noun.hukusi.csv ... 81\n",
            "reading /usr/share/mecab/dic/juman/Prefix.csv ... 90\n",
            "reading /usr/share/mecab/dic/juman/Noun.suusi.csv ... 49\n",
            "reading /usr/share/mecab/dic/juman/Demonstrative.csv ... 97\n",
            "reading /usr/share/mecab/dic/juman/Wikipedia.csv ... 167709\n",
            "reading /usr/share/mecab/dic/juman/Postp.csv ... 108\n",
            "reading /usr/share/mecab/dic/juman/Auto.csv ... 18931\n",
            "reading /usr/share/mecab/dic/juman/Noun.koyuu.csv ... 7964\n",
            "reading /usr/share/mecab/dic/juman/Noun.keishiki.csv ... 8\n",
            "reading /usr/share/mecab/dic/juman/Emoticon.csv ... 972\n",
            "reading /usr/share/mecab/dic/juman/Rengo.csv ... 1118\n",
            "emitting double-array: 100% |###########################################| \n",
            "reading /usr/share/mecab/dic/juman/matrix.def ... 1876x1876\n",
            "emitting matrix      : 100% |###########################################| \n",
            "\n",
            "done!\n",
            "Setting up mecab-ipadic-utf8 (2.7.0-20070801+main-1) ...\n",
            "Compiling IPA dictionary for Mecab.  This takes long time...\n",
            "reading /usr/share/mecab/dic/ipadic/unk.def ... 40\n",
            "emitting double-array: 100% |###########################################| \n",
            "/usr/share/mecab/dic/ipadic/model.def is not found. skipped.\n",
            "reading /usr/share/mecab/dic/ipadic/Suffix.csv ... 1393\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.others.csv ... 151\n",
            "reading /usr/share/mecab/dic/ipadic/Adnominal.csv ... 135\n",
            "reading /usr/share/mecab/dic/ipadic/Adverb.csv ... 3032\n",
            "reading /usr/share/mecab/dic/ipadic/Conjunction.csv ... 171\n",
            "reading /usr/share/mecab/dic/ipadic/Interjection.csv ... 252\n",
            "reading /usr/share/mecab/dic/ipadic/Auxil.csv ... 199\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.demonst.csv ... 120\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.adjv.csv ... 3328\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.number.csv ... 42\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.name.csv ... 34202\n",
            "reading /usr/share/mecab/dic/ipadic/Prefix.csv ... 221\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.nai.csv ... 42\n",
            "reading /usr/share/mecab/dic/ipadic/Verb.csv ... 130750\n",
            "reading /usr/share/mecab/dic/ipadic/Adj.csv ... 27210\n",
            "reading /usr/share/mecab/dic/ipadic/Postp.csv ... 146\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.adverbal.csv ... 795\n",
            "reading /usr/share/mecab/dic/ipadic/Filler.csv ... 19\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.proper.csv ... 27327\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.place.csv ... 72999\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.org.csv ... 16668\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.verbal.csv ... 12146\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.csv ... 60477\n",
            "reading /usr/share/mecab/dic/ipadic/Others.csv ... 2\n",
            "reading /usr/share/mecab/dic/ipadic/Symbol.csv ... 208\n",
            "reading /usr/share/mecab/dic/ipadic/Postp-col.csv ... 91\n",
            "emitting double-array: 100% |###########################################| \n",
            "reading /usr/share/mecab/dic/ipadic/matrix.def ... 1316x1316\n",
            "emitting matrix      : 100% |###########################################| \n",
            "\n",
            "done!\n",
            "update-alternatives: using /var/lib/mecab/dic/ipadic-utf8 to provide /var/lib/mecab/dic/debian (mecab-dictionary) in auto mode\n",
            "Setting up mecab (0.996-5) ...\n",
            "Compiling IPA dictionary for Mecab.  This takes long time...\n",
            "reading /usr/share/mecab/dic/ipadic/unk.def ... 40\n",
            "emitting double-array: 100% |###########################################| \n",
            "/usr/share/mecab/dic/ipadic/model.def is not found. skipped.\n",
            "reading /usr/share/mecab/dic/ipadic/Suffix.csv ... 1393\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.others.csv ... 151\n",
            "reading /usr/share/mecab/dic/ipadic/Adnominal.csv ... 135\n",
            "reading /usr/share/mecab/dic/ipadic/Adverb.csv ... 3032\n",
            "reading /usr/share/mecab/dic/ipadic/Conjunction.csv ... 171\n",
            "reading /usr/share/mecab/dic/ipadic/Interjection.csv ... 252\n",
            "reading /usr/share/mecab/dic/ipadic/Auxil.csv ... 199\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.demonst.csv ... 120\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.adjv.csv ... 3328\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.number.csv ... 42\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.name.csv ... 34202\n",
            "reading /usr/share/mecab/dic/ipadic/Prefix.csv ... 221\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.nai.csv ... 42\n",
            "reading /usr/share/mecab/dic/ipadic/Verb.csv ... 130750\n",
            "reading /usr/share/mecab/dic/ipadic/Adj.csv ... 27210\n",
            "reading /usr/share/mecab/dic/ipadic/Postp.csv ... 146\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.adverbal.csv ... 795\n",
            "reading /usr/share/mecab/dic/ipadic/Filler.csv ... 19\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.proper.csv ... 27327\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.place.csv ... 72999\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.org.csv ... 16668\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.verbal.csv ... 12146\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.csv ... 60477\n",
            "reading /usr/share/mecab/dic/ipadic/Others.csv ... 2\n",
            "reading /usr/share/mecab/dic/ipadic/Symbol.csv ... 208\n",
            "reading /usr/share/mecab/dic/ipadic/Postp-col.csv ... 91\n",
            "emitting double-array: 100% |###########################################| \n",
            "reading /usr/share/mecab/dic/ipadic/matrix.def ... 1316x1316\n",
            "emitting matrix      : 100% |###########################################| \n",
            "\n",
            "done!\n",
            "Setting up mecab-jumandic (7.0-20130310-4) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.6/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n",
            "                            \n",
            "Collecting mecab-python3==0.7\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/25/e9/bbf5fc790a2bedd96fbaf47a84afa060bfb0b3e0217e5f64b32bd4bbad69/mecab-python3-0.7.tar.gz (41kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 2.4MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: mecab-python3\n",
            "  Building wheel for mecab-python3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mecab-python3: filename=mecab_python3-0.7-cp36-cp36m-linux_x86_64.whl size=155493 sha256=a0ab2cb6cc683df457ee4bdb82b82170fcc26ccc66e88f650d1d8a28f8a6b5da\n",
            "  Stored in directory: /root/.cache/pip/wheels/4c/07/3a/5f22ccc9f381f3bc01fa023202061cd1e0e9af855292f005dd\n",
            "Successfully built mecab-python3\n",
            "Installing collected packages: mecab-python3\n",
            "Successfully installed mecab-python3-0.7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RNGZS5goK-3v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import pprint\n",
        "\n",
        "import MeCab\n",
        "\n",
        "from gensim.models import Word2Vec\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn import svm, decomposition\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "from joblib import dump,load"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XPTa_jzUEEVX",
        "colab_type": "code",
        "outputId": "93656f3b-5fda-49df-8a25-7515471e25e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gQgkbgfkej1y",
        "colab_type": "text"
      },
      "source": [
        "# Programs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pSV01cXwhluX",
        "colab_type": "text"
      },
      "source": [
        "## Parsing Input"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QX2DMstkbTFn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#文章を文単位で分割\n",
        "def parse_Paragraph(paragraph):\n",
        "  sentences = re.split('. |。|．|\\.', paragraph)\n",
        "  sentences = [re.sub(',|，', '、',s) for s in sentences]\n",
        "  res = [s+'。' for s in sentences][:-1]\n",
        "  return res"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vqay5MiBa1RV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#mecabで文を分かち書き\n",
        "def parse_Sentence(sentence):\n",
        "  m = MeCab.Tagger(\"-Ochasen\")\n",
        "  parsed = m.parse(sentence)\n",
        "  return parsed"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sl5o6PPvgGt1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#含まれる文を全て分かち書きした文章\n",
        "def parse_Parag_to_Word(paragraph):\n",
        "  sentences = parse_Paragraph(paragraph)\n",
        "  word_parsed_paragraph = [[p.split('\\t') for p in parse_Sentence(s).split('\\n')[:-2]] for s in sentences]\n",
        "  return word_parsed_paragraph"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1k8yWa3KrOws",
        "colab_type": "code",
        "outputId": "aed30b64-dd87-4817-ebb2-f8d77f83d76d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "print(parse_Parag_to_Word(\"図26、図27より、バッファサイズが大きくなる程実行時間が短くなることがわかる.さらにそれぞれの近似曲線より、バッファサイズをx、実行時間をyとすると、両者の関係はy=a/x(aはある特定の定数)という方程式で近似的に表せることができ、実行時間はバッファサイズに反比例していることがわかる.また図27より、read、writeによる実装よりも、fread、fwriteによる実装の方が実行時間が速いことがわかる.実行時間がバッファサイズに反比例したのは、次のような理由が考えられる.cでは、ファイルの内容がバッファサイズごとに読み取り・書き込みが行われる.その処理の回数はバッファサイズに反比例する.よって読み取り・書き込みの回数が増えることによって実行時間が増えると考えられる.read、writeによる実装よりも、fread、fwriteによる実装の方が実行時間が速いのには、以下のような理由が考えられる.cは、両者とも同じバッファサイズで実行しているが、システムコールread、write関数の呼び出し回数が大きく違う.これによって両者の実行時間の違いが出ていると考えられる.\"))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[['図', 'ズ', '図', '名詞-一般', '', ''], ['26', '26', '26', '名詞-数', '', ''], ['、', '、', '、', '記号-読点', '', ''], ['図', 'ズ', '図', '名詞-一般', '', ''], ['27', '27', '27', '名詞-数', '', ''], ['より', 'ヨリ', 'より', '助詞-格助詞-一般', '', ''], ['、', '、', '、', '記号-読点', '', ''], ['バッファ', 'バッファ', 'バッファ', '名詞-一般', '', ''], ['サイズ', 'サイズ', 'サイズ', '名詞-一般', '', ''], ['が', 'ガ', 'が', '助詞-格助詞-一般', '', ''], ['大きく', 'オオキク', '大きい', '形容詞-自立', '形容詞・イ段', '連用テ接続'], ['なる', 'ナル', 'なる', '動詞-自立', '五段・ラ行', '基本形'], ['程', 'ホド', '程', '名詞-非自立-一般', '', ''], ['実行', 'ジッコウ', '実行', '名詞-サ変接続', '', ''], ['時間', 'ジカン', '時間', '名詞-副詞可能', '', ''], ['が', 'ガ', 'が', '助詞-格助詞-一般', '', ''], ['短く', 'ミジカク', '短い', '形容詞-自立', '形容詞・アウオ段', '連用テ接続'], ['なる', 'ナル', 'なる', '動詞-自立', '五段・ラ行', '基本形'], ['こと', 'コト', 'こと', '名詞-非自立-一般', '', ''], ['が', 'ガ', 'が', '助詞-格助詞-一般', '', ''], ['わかる', 'ワカル', 'わかる', '動詞-自立', '五段・ラ行', '基本形'], ['。', '。', '。', '記号-句点', '', '']], [['さらに', 'サラニ', 'さらに', '副詞-助詞類接続', '', ''], ['それぞれ', 'ソレゾレ', 'それぞれ', '名詞-副詞可能', '', ''], ['の', 'ノ', 'の', '助詞-連体化', '', ''], ['近似', 'キンジ', '近似', '名詞-サ変接続', '', ''], ['曲線', 'キョクセン', '曲線', '名詞-一般', '', ''], ['より', 'ヨリ', 'より', '助詞-格助詞-一般', '', ''], ['、', '、', '、', '記号-読点', '', ''], ['バッファ', 'バッファ', 'バッファ', '名詞-一般', '', ''], ['サイズ', 'サイズ', 'サイズ', '名詞-一般', '', ''], ['を', 'ヲ', 'を', '助詞-格助詞-一般', '', ''], ['x', 'x', 'x', '名詞-固有名詞-組織', '', ''], ['、', '、', '、', '記号-読点', '', ''], ['実行', 'ジッコウ', '実行', '名詞-サ変接続', '', ''], ['時間', 'ジカン', '時間', '名詞-副詞可能', '', ''], ['を', 'ヲ', 'を', '助詞-格助詞-一般', '', ''], ['y', 'y', 'y', '名詞-固有名詞-組織', '', ''], ['と', 'ト', 'と', '助詞-格助詞-一般', '', ''], ['する', 'スル', 'する', '動詞-自立', 'サ変・スル', '基本形'], ['と', 'ト', 'と', '助詞-接続助詞', '', ''], ['、', '、', '、', '記号-読点', '', ''], ['両者', 'リョウシャ', '両者', '名詞-一般', '', ''], ['の', 'ノ', 'の', '助詞-連体化', '', ''], ['関係', 'カンケイ', '関係', '名詞-サ変接続', '', ''], ['は', 'ハ', 'は', '助詞-係助詞', '', ''], ['y', 'y', 'y', '名詞-固有名詞-組織', '', ''], ['=', '=', '=', '名詞-サ変接続', '', ''], ['a', 'a', 'a', '名詞-一般', '', ''], ['/', '/', '/', '名詞-サ変接続', '', ''], ['x', 'x', 'x', '名詞-一般', '', ''], ['(', '(', '(', '名詞-サ変接続', '', ''], ['a', 'a', 'a', '名詞-一般', '', ''], ['は', 'ハ', 'は', '助詞-係助詞', '', ''], ['ある', 'アル', 'ある', '動詞-自立', '五段・ラ行', '基本形'], ['特定', 'トクテイ', '特定', '名詞-サ変接続', '', ''], ['の', 'ノ', 'の', '助詞-連体化', '', ''], ['定数', 'テイスウ', '定数', '名詞-一般', '', ''], [')', ')', ')', '名詞-サ変接続', '', ''], ['という', 'トイウ', 'という', '助詞-格助詞-連語', '', ''], ['方程式', 'ホウテイシキ', '方程式', '名詞-一般', '', ''], ['で', 'デ', 'で', '助詞-格助詞-一般', '', ''], ['近似', 'キンジ', '近似', '名詞-サ変接続', '', ''], ['的', 'テキ', '的', '名詞-接尾-形容動詞語幹', '', ''], ['に', 'ニ', 'に', '助詞-副詞化', '', ''], ['表せる', 'アラワセル', '表せる', '動詞-自立', '一段', '基本形'], ['こと', 'コト', 'こと', '名詞-非自立-一般', '', ''], ['が', 'ガ', 'が', '助詞-格助詞-一般', '', ''], ['でき', 'デキ', 'できる', '動詞-自立', '一段', '連用形'], ['、', '、', '、', '記号-読点', '', ''], ['実行', 'ジッコウ', '実行', '名詞-サ変接続', '', ''], ['時間', 'ジカン', '時間', '名詞-副詞可能', '', ''], ['は', 'ハ', 'は', '助詞-係助詞', '', ''], ['バッファ', 'バッファ', 'バッファ', '名詞-一般', '', ''], ['サイズ', 'サイズ', 'サイズ', '名詞-一般', '', ''], ['に', 'ニ', 'に', '助詞-格助詞-一般', '', ''], ['反比例', 'ハンピレイ', '反比例', '名詞-サ変接続', '', ''], ['し', 'シ', 'する', '動詞-自立', 'サ変・スル', '連用形'], ['て', 'テ', 'て', '助詞-接続助詞', '', ''], ['いる', 'イル', 'いる', '動詞-非自立', '一段', '基本形'], ['こと', 'コト', 'こと', '名詞-非自立-一般', '', ''], ['が', 'ガ', 'が', '助詞-格助詞-一般', '', ''], ['わかる', 'ワカル', 'わかる', '動詞-自立', '五段・ラ行', '基本形'], ['。', '。', '。', '記号-句点', '', '']], [['また', 'マタ', 'また', '接続詞', '', ''], ['図', 'ズ', '図', '名詞-一般', '', ''], ['27', '27', '27', '名詞-数', '', ''], ['より', 'ヨリ', 'より', '助詞-格助詞-一般', '', ''], ['、', '、', '、', '記号-読点', '', ''], ['read', 'read', 'read', '名詞-固有名詞-組織', '', ''], ['、', '、', '、', '記号-読点', '', ''], ['write', 'write', 'write', '名詞-固有名詞-組織', '', ''], ['による', 'ニヨル', 'による', '助詞-格助詞-連語', '', ''], ['実装', 'ジッソウ', '実装', '名詞-サ変接続', '', ''], ['より', 'ヨリ', 'より', '助詞-格助詞-一般', '', ''], ['も', 'モ', 'も', '助詞-係助詞', '', ''], ['、', '、', '、', '記号-読点', '', ''], ['fread', 'fread', 'fread', '名詞-固有名詞-組織', '', ''], ['、', '、', '、', '記号-読点', '', ''], ['fwrite', 'fwrite', 'fwrite', '名詞-固有名詞-組織', '', ''], ['による', 'ニヨル', 'による', '助詞-格助詞-連語', '', ''], ['実装', 'ジッソウ', '実装', '名詞-サ変接続', '', ''], ['の', 'ノ', 'の', '助詞-連体化', '', ''], ['方', 'ホウ', '方', '名詞-非自立-一般', '', ''], ['が', 'ガ', 'が', '助詞-格助詞-一般', '', ''], ['実行', 'ジッコウ', '実行', '名詞-サ変接続', '', ''], ['時間', 'ジカン', '時間', '名詞-副詞可能', '', ''], ['が', 'ガ', 'が', '助詞-格助詞-一般', '', ''], ['速い', 'ハヤイ', '速い', '形容詞-自立', '形容詞・アウオ段', '基本形'], ['こと', 'コト', 'こと', '名詞-非自立-一般', '', ''], ['が', 'ガ', 'が', '助詞-格助詞-一般', '', ''], ['わかる', 'ワカル', 'わかる', '動詞-自立', '五段・ラ行', '基本形'], ['。', '。', '。', '記号-句点', '', '']], [['実行', 'ジッコウ', '実行', '名詞-サ変接続', '', ''], ['時間', 'ジカン', '時間', '名詞-副詞可能', '', ''], ['が', 'ガ', 'が', '助詞-格助詞-一般', '', ''], ['バッファ', 'バッファ', 'バッファ', '名詞-一般', '', ''], ['サイズ', 'サイズ', 'サイズ', '名詞-一般', '', ''], ['に', 'ニ', 'に', '助詞-格助詞-一般', '', ''], ['反比例', 'ハンピレイ', '反比例', '名詞-サ変接続', '', ''], ['し', 'シ', 'する', '動詞-自立', 'サ変・スル', '連用形'], ['た', 'タ', 'た', '助動詞', '特殊・タ', '基本形'], ['の', 'ノ', 'の', '名詞-非自立-一般', '', ''], ['は', 'ハ', 'は', '助詞-係助詞', '', ''], ['、', '、', '、', '記号-読点', '', ''], ['次', 'ツギ', '次', '名詞-一般', '', ''], ['の', 'ノ', 'の', '助詞-連体化', '', ''], ['よう', 'ヨウ', 'よう', '名詞-非自立-助動詞語幹', '', ''], ['な', 'ナ', 'だ', '助動詞', '特殊・ダ', '体言接続'], ['理由', 'リユウ', '理由', '名詞-一般', '', ''], ['が', 'ガ', 'が', '助詞-格助詞-一般', '', ''], ['考え', 'カンガエ', '考える', '動詞-自立', '一段', '未然形'], ['られる', 'ラレル', 'られる', '動詞-接尾', '一段', '基本形'], ['。', '。', '。', '記号-句点', '', '']], [['c', 'c', 'c', '名詞-一般', '', ''], ['で', 'デ', 'で', '助詞-格助詞-一般', '', ''], ['は', 'ハ', 'は', '助詞-係助詞', '', ''], ['、', '、', '、', '記号-読点', '', ''], ['ファイル', 'ファイル', 'ファイル', '名詞-一般', '', ''], ['の', 'ノ', 'の', '助詞-連体化', '', ''], ['内容', 'ナイヨウ', '内容', '名詞-一般', '', ''], ['が', 'ガ', 'が', '助詞-格助詞-一般', '', ''], ['バッファ', 'バッファ', 'バッファ', '名詞-一般', '', ''], ['サイズ', 'サイズ', 'サイズ', '名詞-一般', '', ''], ['ごと', 'ゴト', 'ごと', '名詞-接尾-一般', '', ''], ['に', 'ニ', 'に', '助詞-格助詞-一般', '', ''], ['読み取り', 'ヨミトリ', '読み取る', '動詞-自立', '五段・ラ行', '連用形'], ['・', '・', '・', '記号-一般', '', ''], ['書き込み', 'カキコミ', '書き込み', '名詞-一般', '', ''], ['が', 'ガ', 'が', '助詞-格助詞-一般', '', ''], ['行わ', 'オコナワ', '行う', '動詞-自立', '五段・ワ行促音便', '未然形'], ['れる', 'レル', 'れる', '動詞-接尾', '一段', '基本形'], ['。', '。', '。', '記号-句点', '', '']], [['その', 'ソノ', 'その', '連体詞', '', ''], ['処理', 'ショリ', '処理', '名詞-サ変接続', '', ''], ['の', 'ノ', 'の', '助詞-連体化', '', ''], ['回数', 'カイスウ', '回数', '名詞-一般', '', ''], ['は', 'ハ', 'は', '助詞-係助詞', '', ''], ['バッファ', 'バッファ', 'バッファ', '名詞-一般', '', ''], ['サイズ', 'サイズ', 'サイズ', '名詞-一般', '', ''], ['に', 'ニ', 'に', '助詞-格助詞-一般', '', ''], ['反比例', 'ハンピレイ', '反比例', '名詞-サ変接続', '', ''], ['する', 'スル', 'する', '動詞-自立', 'サ変・スル', '基本形'], ['。', '。', '。', '記号-句点', '', '']], [['よって', 'ヨッテ', 'よって', '接続詞', '', ''], ['読み取り', 'ヨミトリ', '読み取り', '名詞-一般', '', ''], ['・', '・', '・', '記号-一般', '', ''], ['書き込み', 'カキコミ', '書き込み', '名詞-一般', '', ''], ['の', 'ノ', 'の', '助詞-連体化', '', ''], ['回数', 'カイスウ', '回数', '名詞-一般', '', ''], ['が', 'ガ', 'が', '助詞-格助詞-一般', '', ''], ['増える', 'フエル', '増える', '動詞-自立', '一段', '基本形'], ['こと', 'コト', 'こと', '名詞-非自立-一般', '', ''], ['によって', 'ニヨッテ', 'によって', '助詞-格助詞-連語', '', ''], ['実行', 'ジッコウ', '実行', '名詞-サ変接続', '', ''], ['時間', 'ジカン', '時間', '名詞-副詞可能', '', ''], ['が', 'ガ', 'が', '助詞-格助詞-一般', '', ''], ['増える', 'フエル', '増える', '動詞-自立', '一段', '基本形'], ['と', 'ト', 'と', '助詞-格助詞-引用', '', ''], ['考え', 'カンガエ', '考える', '動詞-自立', '一段', '未然形'], ['られる', 'ラレル', 'られる', '動詞-接尾', '一段', '基本形'], ['。', '。', '。', '記号-句点', '', '']], [['read', 'read', 'read', '名詞-固有名詞-組織', '', ''], ['、', '、', '、', '記号-読点', '', ''], ['write', 'write', 'write', '名詞-固有名詞-組織', '', ''], ['による', 'ニヨル', 'による', '助詞-格助詞-連語', '', ''], ['実装', 'ジッソウ', '実装', '名詞-サ変接続', '', ''], ['より', 'ヨリ', 'より', '助詞-格助詞-一般', '', ''], ['も', 'モ', 'も', '助詞-係助詞', '', ''], ['、', '、', '、', '記号-読点', '', ''], ['fread', 'fread', 'fread', '名詞-固有名詞-組織', '', ''], ['、', '、', '、', '記号-読点', '', ''], ['fwrite', 'fwrite', 'fwrite', '名詞-固有名詞-組織', '', ''], ['による', 'ニヨル', 'による', '助詞-格助詞-連語', '', ''], ['実装', 'ジッソウ', '実装', '名詞-サ変接続', '', ''], ['の', 'ノ', 'の', '助詞-連体化', '', ''], ['方', 'ホウ', '方', '名詞-非自立-一般', '', ''], ['が', 'ガ', 'が', '助詞-格助詞-一般', '', ''], ['実行', 'ジッコウ', '実行', '名詞-サ変接続', '', ''], ['時間', 'ジカン', '時間', '名詞-副詞可能', '', ''], ['が', 'ガ', 'が', '助詞-格助詞-一般', '', ''], ['速い', 'ハヤイ', '速い', '形容詞-自立', '形容詞・アウオ段', '基本形'], ['の', 'ノ', 'の', '名詞-非自立-一般', '', ''], ['に', 'ニ', 'に', '助詞-格助詞-一般', '', ''], ['は', 'ハ', 'は', '助詞-係助詞', '', ''], ['、', '、', '、', '記号-読点', '', ''], ['以下', 'イカ', '以下', '名詞-非自立-副詞可能', '', ''], ['の', 'ノ', 'の', '助詞-連体化', '', ''], ['よう', 'ヨウ', 'よう', '名詞-非自立-助動詞語幹', '', ''], ['な', 'ナ', 'だ', '助動詞', '特殊・ダ', '体言接続'], ['理由', 'リユウ', '理由', '名詞-一般', '', ''], ['が', 'ガ', 'が', '助詞-格助詞-一般', '', ''], ['考え', 'カンガエ', '考える', '動詞-自立', '一段', '未然形'], ['られる', 'ラレル', 'られる', '動詞-接尾', '一段', '基本形'], ['。', '。', '。', '記号-句点', '', '']], [['c', 'c', 'c', '名詞-固有名詞-組織', '', ''], ['は', 'ハ', 'は', '助詞-係助詞', '', ''], ['、', '、', '、', '記号-読点', '', ''], ['両者', 'リョウシャ', '両者', '名詞-一般', '', ''], ['とも', 'トモ', 'とも', '助詞-副助詞', '', ''], ['同じ', 'オナジ', '同じ', '連体詞', '', ''], ['バッファ', 'バッファ', 'バッファ', '名詞-一般', '', ''], ['サイズ', 'サイズ', 'サイズ', '名詞-一般', '', ''], ['で', 'デ', 'で', '助詞-格助詞-一般', '', ''], ['実行', 'ジッコウ', '実行', '名詞-サ変接続', '', ''], ['し', 'シ', 'する', '動詞-自立', 'サ変・スル', '連用形'], ['て', 'テ', 'て', '助詞-接続助詞', '', ''], ['いる', 'イル', 'いる', '動詞-非自立', '一段', '基本形'], ['が', 'ガ', 'が', '助詞-接続助詞', '', ''], ['、', '、', '、', '記号-読点', '', ''], ['システム', 'システム', 'システム', '名詞-一般', '', ''], ['コール', 'コール', 'コール', '名詞-固有名詞-人名-姓', '', ''], ['read', 'read', 'read', '名詞-固有名詞-組織', '', ''], ['、', '、', '、', '記号-読点', '', ''], ['write', 'write', 'write', '名詞-固有名詞-組織', '', ''], ['関数', 'カンスウ', '関数', '名詞-一般', '', ''], ['の', 'ノ', 'の', '助詞-連体化', '', ''], ['呼び出し', 'ヨビダシ', '呼び出し', '名詞-サ変接続', '', ''], ['回数', 'カイスウ', '回数', '名詞-一般', '', ''], ['が', 'ガ', 'が', '助詞-格助詞-一般', '', ''], ['大きく', 'オオキク', '大きい', '形容詞-自立', '形容詞・イ段', '連用テ接続'], ['違う', 'チガウ', '違う', '動詞-自立', '五段・ワ行促音便', '基本形'], ['。', '。', '。', '記号-句点', '', '']], [['これ', 'コレ', 'これ', '名詞-代名詞-一般', '', ''], ['によって', 'ニヨッテ', 'によって', '助詞-格助詞-連語', '', ''], ['両者', 'リョウシャ', '両者', '名詞-一般', '', ''], ['の', 'ノ', 'の', '助詞-連体化', '', ''], ['実行', 'ジッコウ', '実行', '名詞-サ変接続', '', ''], ['時間', 'ジカン', '時間', '名詞-副詞可能', '', ''], ['の', 'ノ', 'の', '助詞-連体化', '', ''], ['違い', 'チガイ', '違い', '名詞-ナイ形容詞語幹', '', ''], ['が', 'ガ', 'が', '助詞-格助詞-一般', '', ''], ['出', 'デ', '出る', '動詞-自立', '一段', '連用形'], ['て', 'テ', 'て', '助詞-接続助詞', '', ''], ['いる', 'イル', 'いる', '動詞-非自立', '一段', '基本形'], ['と', 'ト', 'と', '助詞-格助詞-引用', '', ''], ['考え', 'カンガエ', '考える', '動詞-自立', '一段', '未然形'], ['られる', 'ラレル', 'られる', '動詞-接尾', '一段', '基本形'], ['。', '。', '。', '記号-句点', '', '']]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BOiqwXlea03n",
        "colab_type": "text"
      },
      "source": [
        "## 要素分類(import Parsing Input)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LmuZD0xfLRH7",
        "colab_type": "text"
      },
      "source": [
        "Content_Classification(paragraph): 引数に文章を入れて分類結果リストを得る"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "olYUft1McgMv",
        "colab_type": "text"
      },
      "source": [
        "### DataPath"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XlmTWqUYcfy5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#点数データのパス\n",
        "path_Content_points = \"gdrive/My Drive/Colab Notebooks/研究/data/data_prot/Rules/Content_points.csv\"\n",
        "#要素分類モデル\n",
        "path_sentence_attr_model = \"gdrive/My Drive/Colab Notebooks/研究/data/Statement_attributes/model_svc.model\"\n",
        "#w2vモデル\n",
        "path_wv_model = \"gdrive/My Drive/Colab Notebooks/研究/data/word2vec.model\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MRJ-CVE5dTef",
        "colab_type": "code",
        "outputId": "95e4cb86-3441-46fb-bcc8-f02d9142f323",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        }
      },
      "source": [
        "df_Content_points = pd.read_csv(path_Content_points)\n",
        "df_Content_points.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>from</th>\n",
              "      <th>to</th>\n",
              "      <th>point</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>claim</td>\n",
              "      <td>claim</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>claim</td>\n",
              "      <td>ground</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ground</td>\n",
              "      <td>claim</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ground</td>\n",
              "      <td>ground</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     from      to  point\n",
              "0   claim   claim      5\n",
              "1   claim  ground      0\n",
              "2  ground   claim      7\n",
              "3  ground  ground      5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nN2wH-_LMh6Y",
        "colab_type": "text"
      },
      "source": [
        "### Load Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wfe6GZiA5iQ3",
        "colab_type": "code",
        "outputId": "bb08fc05-8a6e-46bd-bc1c-a71940de0d42",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        }
      },
      "source": [
        "#要素分類モデル読み込み\n",
        "sentence_attr_model = load(path_sentence_attr_model)\n",
        "pprint.pprint(SVC.get_params(sentence_attr_model,deep=True))\n",
        "#w2vモデル読み込み\n",
        "wv_model = Word2Vec.load(path_wv_model)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'C': 1.0,\n",
            " 'break_ties': False,\n",
            " 'cache_size': 200,\n",
            " 'class_weight': None,\n",
            " 'coef0': 0.0,\n",
            " 'decision_function_shape': 'ovr',\n",
            " 'degree': 3,\n",
            " 'gamma': 'scale',\n",
            " 'kernel': 'rbf',\n",
            " 'max_iter': -1,\n",
            " 'probability': True,\n",
            " 'random_state': None,\n",
            " 'shrinking': True,\n",
            " 'tol': 0.001,\n",
            " 'verbose': False}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:410: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QOx3MdNyBxFR",
        "colab_type": "text"
      },
      "source": [
        "### 主成分分析"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iDxtSZ3wB7kL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pca_vec(vec):\n",
        "  vec_ = np.array([vec[:,n] for n in range(len(vec[0])-1)])\n",
        "  pca = decomposition.PCA(n_components=1)\n",
        "  vec_transformed = pca.fit_transform(vec_)\n",
        "  return vec_transformed[:,0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0HuGcVbB47o",
        "colab_type": "text"
      },
      "source": [
        "### mecabの分かち書きからベクトル生成"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gyOxCaUhCBsH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_vec(sentence, wv_model):\n",
        "  vec = np.array([wv_model.wv[w] for w in [sentence[n][0] for n in range(len(sentence)-1)]])\n",
        "  return pca_vec(vec)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iXw4kAcU__au",
        "colab_type": "text"
      },
      "source": [
        "### Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eHjj4zBxknLW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#文単位で分割された文章を入力　推測の結果をリストで返す\n",
        "def predict_Sentence_attr(vec, model):\n",
        "  prediction = model.predict(vec).astype(int)\n",
        "  print(prediction[0])\n",
        "  prediction = np.where(prediction==0, 'claim', prediction)\n",
        "  prediction = np.where(prediction=='-1', 'ground', prediction)\n",
        "  prediction = np.where(prediction=='1', 'ground', prediction)\n",
        "  prediction = np.where(prediction=='2', 'ground', prediction)\n",
        "  return prediction.tolist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "onPy0rEV-1EV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Content_Classification(paragraph):\n",
        "  parsed = parse_Parag_to_Word(paragraph)\n",
        "  arr_attr = []\n",
        "  for p in parsed:\n",
        "    vec = make_vec(p, wv_model)\n",
        "    arr_attr.append(predict_Sentence_attr(vec.reshape(1,-1), sentence_attr_model)[0])\n",
        "  return arr_attr"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UHdneGzwMYbC",
        "colab_type": "text"
      },
      "source": [
        "### Sample"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oxze5xVqLcPD",
        "colab_type": "code",
        "outputId": "20b46a18-f126-48d6-9293-238b22c8bb8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        }
      },
      "source": [
        "Content_Classification(\"図26、図27より、バッファサイズが大きくなる程実行時間が短くなることがわかる.さらにそれぞれの近似曲線より、バッファサイズをx、実行時間をyとすると、両者の関係はy=a/x(aはある特定の定数)という方程式で近似的に表せることができ、実行時間はバッファサイズに反比例していることがわかる.また図27より、read、writeによる実装よりも、fread、fwriteによる実装の方が実行時間が速いことがわかる.実行時間がバッファサイズに反比例したのは、次のような理由が考えられる.cでは、ファイルの内容がバッファサイズごとに読み取り・書き込みが行われる.その処理の回数はバッファサイズに反比例する.よって読み取り・書き込みの回数が増えることによって実行時間が増えると考えられる.read、writeによる実装よりも、fread、fwriteによる実装の方が実行時間が速いのには、以下のような理由が考えられる.cは、両者とも同じバッファサイズで実行しているが、システムコールread、write関数の呼び出し回数が大きく違う.これによって両者の実行時間の違いが出ていると考えられる.\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "1\n",
            "1\n",
            "1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['ground',\n",
              " 'ground',\n",
              " 'ground',\n",
              " 'ground',\n",
              " 'ground',\n",
              " 'ground',\n",
              " 'claim',\n",
              " 'ground',\n",
              " 'ground',\n",
              " 'ground']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j3Lt7ixy7pTo",
        "colab_type": "text"
      },
      "source": [
        "### 加点行列をつくる"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQR_B0GY7oGm",
        "colab_type": "code",
        "outputId": "25c9eed6-1cb9-4a26-a6a7-d95e24ab4ad1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "def Content_addmat(arr_content, matsize, df_Content_points):\n",
        "  points_mat = np.zeros((matsize, matsize), dtype=int)\n",
        "  for i in range(matsize):\n",
        "    for j in range(i+1, matsize):\n",
        "      if i != j:\n",
        "        res = df_Content_points[df_Content_points['from']==arr_content[i]]\n",
        "        res = res[res['to']==arr_content[j]]\n",
        "        points_mat[i][j] = res[\"point\"]+i-j+1\n",
        "        points_mat[j][i] = res[\"point\"]+i-j+1\n",
        "  return points_mat\n",
        "  \n",
        "Content_addmat([\"ground\", \"ground\", \"ground\", \"ground\", \"claim\"],5, df_Content_points)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 5, 4, 3, 4],\n",
              "       [5, 0, 5, 4, 5],\n",
              "       [4, 5, 0, 5, 6],\n",
              "       [3, 4, 5, 0, 7],\n",
              "       [4, 5, 6, 7, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hyx7TJh13UNT",
        "colab_type": "text"
      },
      "source": [
        "## 接続詞(import Parsing Input, 要素分類)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "arKQLW_xEKaE",
        "colab_type": "text"
      },
      "source": [
        "### Datapath"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3wVRxNeTEHUJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#接続関係と点数データのパス\n",
        "path_Conjuction_attr =  \"gdrive/My Drive/Colab Notebooks/研究/data/data_prot/Rules/Conjuction_attr.csv\"\n",
        "path_Conjuction_points =  \"gdrive/My Drive/Colab Notebooks/研究/data/data_prot/Rules/Conjuction_points.csv\"\n",
        "#山本 和英, 齋藤 真実の分類\n",
        "path_Conjuction_attr_yamamoto =  \"gdrive/My Drive/Colab Notebooks/研究/data/data_prot/Yamamoto_Rules/Conjuction_attr.csv\"\n",
        "path_Conjuction_points_yamamoto =  \"gdrive/My Drive/Colab Notebooks/研究/data/data_prot/Yamamoto_Rules/Conjuction_points.csv\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UIynxCRKZfQD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_conjuction_attr = pd.read_csv(path_Conjuction_attr)\n",
        "df_conjuction_points = pd.read_csv(path_Conjuction_points)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3OfjDalKn2yk",
        "colab_type": "text"
      },
      "source": [
        "### Preview"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lslR9I70hqFk",
        "colab_type": "code",
        "outputId": "9cd67896-32d6-4ed5-980a-3638e26cad80",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "source": [
        "df_conjuction_attr.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word</th>\n",
              "      <th>attr</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>かくして</td>\n",
              "      <td>解説</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>すると</td>\n",
              "      <td>解説</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>然し乍ら</td>\n",
              "      <td>制限</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>即ち</td>\n",
              "      <td>解説</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>けれども</td>\n",
              "      <td>制限</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   word attr\n",
              "0  かくして   解説\n",
              "1   すると   解説\n",
              "2  然し乍ら   制限\n",
              "3    即ち   解説\n",
              "4  けれども   制限"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "htSWMSQuhrtH",
        "colab_type": "code",
        "outputId": "575b62ca-e923-4797-9e04-028446d7bb9b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        }
      },
      "source": [
        "df_conjuction_points.head(20)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>attr</th>\n",
              "      <th>if_loc</th>\n",
              "      <th>if_is</th>\n",
              "      <th>point</th>\n",
              "      <th>from_start</th>\n",
              "      <th>from_end</th>\n",
              "      <th>to_start</th>\n",
              "      <th>to_end</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>解説</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-2</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>解説</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>20</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>対比</td>\n",
              "      <td>1.0</td>\n",
              "      <td>claim</td>\n",
              "      <td>10</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>対比</td>\n",
              "      <td>1.0</td>\n",
              "      <td>ground</td>\n",
              "      <td>10</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>例示</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-2</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>例示</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>20</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>付加</td>\n",
              "      <td>1.0</td>\n",
              "      <td>claim</td>\n",
              "      <td>10</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>付加</td>\n",
              "      <td>1.0</td>\n",
              "      <td>ground</td>\n",
              "      <td>5</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>転換</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-40</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>制限</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>10</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>譲歩</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>10</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   attr  if_loc   if_is  point  from_start  from_end  to_start  to_end\n",
              "0    解説     NaN     NaN      0         NaN        -2         0     0.0\n",
              "1    解説     NaN     NaN     20         0.0         0        -1    -1.0\n",
              "2    対比     1.0   claim     10        -1.0         0         1     1.0\n",
              "3    対比     1.0  ground     10        -1.0         0         1     1.0\n",
              "4    例示     NaN     NaN     -5         NaN        -2         0     0.0\n",
              "5    例示     NaN     NaN     20         0.0         0        -1    -1.0\n",
              "6    付加     1.0   claim     10        -1.0         0         1     1.0\n",
              "7    付加     1.0  ground      5        -1.0        -1         0     0.0\n",
              "8    転換     NaN     NaN    -40         NaN        -1         0     NaN\n",
              "9    制限     NaN     NaN     10         0.0         0         1     1.0\n",
              "10   譲歩     NaN     NaN     10         0.0         0         1     1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4KXrWOYyn7o5",
        "colab_type": "text"
      },
      "source": [
        "### 文頭の接続詞から属性探索"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NathSu41gfIn",
        "colab_type": "code",
        "outputId": "82709145-21f5-479b-aafa-1420981f2719",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 95
        }
      },
      "source": [
        "def search_Conjuction(df_attr, sentence):\n",
        "  if '接続詞' in sentence[0][3]:\n",
        "    query = 'word == \\\"'+sentence[0][0]+'\\\"'\n",
        "    arr_attr = df_attr.query(query)\n",
        "    print(sentence[0][0],\" is \", arr_attr[\"attr\"].tolist())\n",
        "    return arr_attr\n",
        "  else:\n",
        "    return 0\n",
        "\n",
        "sentence = parse_Parag_to_Word(\"なんだかやる気が出ないお。よって、私は飯を食い床に就く。\")\n",
        "search_Conjuction(df_conjuction_attr, sentence[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "よって  is  ['解説']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word</th>\n",
              "      <th>attr</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>よって</td>\n",
              "      <td>解説</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   word attr\n",
              "52  よって   解説"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qbFqGytJpGcZ",
        "colab_type": "text"
      },
      "source": [
        "### 属性からルール探索"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Kz5cofqpGPc",
        "colab_type": "code",
        "outputId": "a1b4f471-b000-47dd-e192-cb906841ea5b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "def search_Rules(df_rules, attr):\n",
        "  arr_rules = pd.DataFrame()\n",
        "  if attr is not 0:\n",
        "    query = 'attr == \\\"'+attr['attr']+'\\\"'\n",
        "    res = df_rules.query(query)\n",
        "    arr_rules = pd.concat([arr_rules,res], axis=0)\n",
        "  return arr_rules  \n",
        "\n",
        "sentence = parse_Parag_to_Word(\"なんだかやる気が出ないお。よって私は飯を食い床に就く。\")\n",
        "attrs = search_Conjuction(df_conjuction_attr, sentence[1])\n",
        "for index, attr in attrs.iterrows():\n",
        "#  print(index,attr)\n",
        "  rules = search_Rules(df_conjuction_points, attr)\n",
        "  print(rules.head())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "よって  is  ['解説']\n",
            "  attr  if_loc if_is  point  from_start  from_end  to_start  to_end\n",
            "0   解説     NaN   NaN      0         NaN        -2         0     0.0\n",
            "1   解説     NaN   NaN     20         0.0         0        -1    -1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mcUXCUJ3yLD",
        "colab_type": "text"
      },
      "source": [
        "### 加点行列をつくる"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CPSNmqGO2VxC",
        "colab_type": "code",
        "outputId": "b74db8af-a44e-455d-da22-a4e53c10a9b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "#search_ConjuctionからDataFrame.iterrows()でiterateしてattrでrsearch_Rulesから抽出適用・構造候補の加点行列を作る\n",
        "def Conjuction_addmat(rules, matsize, cur, arr_attr):\n",
        "  points_mat = np.zeros((matsize, matsize), dtype=int)\n",
        "  rules['from_start'] = rules['from_start'].fillna(-cur)\n",
        "  rules['from_end'] = rules['from_end'].fillna(-cur)\n",
        "  rules['to_start'] = rules['to_start'].fillna(-cur)\n",
        "  rules['to_end'] = rules['to_end'].fillna(matsize)\n",
        "#  print(rules)\n",
        "  for index, rule in rules.iterrows():\n",
        "#    print(rule)\n",
        "    point = int(rule['point'])\n",
        "    adder_fromstart = cur + int(rule['from_start'])\n",
        "    adder_fromend = cur + int(rule['from_end'])+1\n",
        "    adder_tostart = cur + int(rule['to_start'])\n",
        "    adder_toend = cur + int(rule['to_end'])+1\n",
        "    \n",
        "    if np.isnan(rule['if_loc']) != True:\n",
        "      if arr_attr[cur+int(rule['if_loc'])] == rule['if_is']:\n",
        "        print(point,\"points [\",adder_fromstart,\":\",adder_fromend,\"] to [\",adder_tostart,\":\",adder_toend,\"] with \\\"\", rules['attr'].tolist()[0],\"\\\"\")\n",
        "#        print(points_mat[adder_fromstart:adder_fromend][adder_tostart:adder_toend])\n",
        "        points_mat[adder_fromstart:adder_fromend,adder_tostart:adder_toend] += point\n",
        "        points_mat[adder_tostart:adder_toend,adder_fromstart:adder_fromend] += point\n",
        "    else:\n",
        "      print(point,\"points [\",adder_fromstart,\":\",adder_fromend,\"] to [\",adder_tostart,\":\",adder_toend,\"] with \\\"\", rules['attr'].tolist()[0],\"\\\"\")\n",
        "      points_mat[adder_fromstart:adder_fromend,adder_tostart:adder_toend] += point\n",
        "      points_mat[adder_tostart:adder_toend,adder_fromstart:adder_fromend] += point\n",
        "#    print(points_mat,\"\\n\")\n",
        "  return points_mat\n",
        "\n",
        "Conjuction_addmat(rules, 5, 3, [\"ground\", \"ground\", \"ground\", \"ground\", \"claim\"])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 points [ 0 : 2 ] to [ 3 : 4 ] with \" 解説 \"\n",
            "20 points [ 3 : 4 ] to [ 2 : 3 ] with \" 解説 \"\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0,  0,  0,  0,  0],\n",
              "       [ 0,  0,  0,  0,  0],\n",
              "       [ 0,  0,  0, 20,  0],\n",
              "       [ 0,  0, 20,  0,  0],\n",
              "       [ 0,  0,  0,  0,  0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ngJgOjZwUCbk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Paragraph_to_Conjuction_addmat(df_conjuction_attr, df_conjuction_points, sentences, arr_content):\n",
        "  len_sentence = len(sentences)\n",
        "  addmat = np.zeros((len(sentences), len(sentences)), dtype=int)\n",
        "  cases = pd.DataFrame({'matrix':[addmat], 'label':['']})\n",
        "\n",
        "  def makemat(s, attr):\n",
        "    label = str(str(s+1)+\"文目:「\"+attr['word']+\"」が\"+attr['attr']+\"\\n\")\n",
        "    #接続関係とルールのマッチング\n",
        "    rules = search_Rules(df_conjuction_points, attr)\n",
        "    mat = Conjuction_addmat(rules, len_sentence, s, arr_content)\n",
        "    pprint.pprint(mat)\n",
        "    return label, mat\n",
        "\n",
        "  for s in range(len_sentence):\n",
        "    #単語と接続関係のマッチング\n",
        "#    print(sentences[s])\n",
        "    arr_attr = search_Conjuction(df_conjuction_attr, sentences[s])\n",
        "    if type(arr_attr) is not int:\n",
        "        base0 = cases.copy()\n",
        "        cases.drop(cases.index, inplace=True)\n",
        "        for index, attr in arr_attr.iterrows():\n",
        "            label, matrix = makemat(s, attr)    \n",
        "            base1 = base0.copy()\n",
        "            base1['matrix'] = base1['matrix'].map(lambda x: x + matrix)\n",
        "            base1['label'] = base1['label'].map(lambda x: x + label)\n",
        "            cases = pd.concat([cases, base1])\n",
        "    \n",
        "  return cases"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OREpPvV81StC",
        "colab_type": "text"
      },
      "source": [
        "## 指示語"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D96-RQGd1ZoO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Directive_addmat(sentences, matsize, point):\n",
        "  points_mat = np.zeros((matsize, matsize), dtype=int)\n",
        "  for s in range(1,len(sentences)):\n",
        "    if re.match(\"この|あの|その|これ|それ\",sentences[s][0][0]):\n",
        "      print(sentences[s][0][0], \" in \", s, \"文目\")\n",
        "      points_mat[s-1][s] += point\n",
        "      points_mat[s][s-1] += point\n",
        "  print(points_mat)\n",
        "  return points_mat"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zwHRBfSebJwB",
        "colab_type": "text"
      },
      "source": [
        "## 他キーワード"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7zHV5Mv1hno6",
        "colab_type": "code",
        "outputId": "9fe4362d-5536-4b4b-c939-57c3a03acc02",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#単語一覧のパス\n",
        "path_Keywords = \"gdrive/My Drive/Colab Notebooks/研究/data/data_prot/Rules/Keywords.csv\"\n",
        "\n",
        "df_keywords = pd.read_csv(path_Keywords)\n",
        "df_keywords.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word</th>\n",
              "      <th>point</th>\n",
              "      <th>from</th>\n",
              "      <th>to</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>同様</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>次</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>以下</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>さらに</td>\n",
              "      <td>10</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  word  point  from  to\n",
              "0   同様     10     0   1\n",
              "1    次     10     0   1\n",
              "2   以下     10     0   1\n",
              "3  さらに     10    -1   0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pq2QS4yTbSRP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Keyword_addmat(sentences, matsize, df_keywords):\n",
        "  points_mat = np.zeros((matsize, matsize), dtype=int)\n",
        "  for s in range(len(sentences)-1):\n",
        "    for index, row in df_keywords.iterrows():\n",
        "      keyword = row[\"word\"]\n",
        "      point = row[\"point\"]\n",
        "      for w in sentences[s]:\n",
        "        if keyword in w[0]:\n",
        "          print(keyword, \" in \", s, \"文目\")\n",
        "          points_mat[s+row[\"from\"]][s+row[\"to\"]] += point\n",
        "          points_mat[s+row[\"to\"]][s+row[\"from\"]] += point\n",
        "  print(points_mat)\n",
        "  return points_mat"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v9q375a-oZ4g",
        "colab_type": "text"
      },
      "source": [
        "## 共通の単語"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZgpUxiUOsbTh",
        "colab_type": "code",
        "outputId": "73b81883-079f-4e80-9311-574773386aeb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "source": [
        "#単語一覧のパス\n",
        "path_Exeptwords = \"gdrive/My Drive/Colab Notebooks/研究/data/data_prot/Rules/Exeptwords.csv\"\n",
        "\n",
        "df_exeptwords = pd.read_csv(path_Exeptwords)\n",
        "df_exeptwords.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>考え</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>考える</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>する</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>いる</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>なる</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  word\n",
              "0   考え\n",
              "1  考える\n",
              "2   する\n",
              "3   いる\n",
              "4   なる"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hD1s4iL7ocCo",
        "colab_type": "code",
        "outputId": "74fa6018-e429-49ab-cac1-127d0c26a2e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        }
      },
      "source": [
        "def Commonword_addmat(sentences, matsize, df_exeptwords, coef, thres):\n",
        "  points_mat = np.zeros((matsize, matsize), dtype=int)\n",
        "  per_mat = np.zeros((matsize, matsize), dtype=float)\n",
        "  arr_exeptword = df_exeptwords[\"word\"].tolist()\n",
        "\n",
        "  def extract_words(sentence):\n",
        "    s =[]\n",
        "    for w in sentence:\n",
        "     if re.match('名詞|動詞|形容詞|形容動詞', w[3]):\n",
        "       s.append(w[0])\n",
        "    sentence_words = list(set(s) - set(arr_exeptword))\n",
        "    return sentence_words\n",
        "\n",
        "  def compare_sentences(sentence1, sentence2):\n",
        "    arr_commonwords = list(set(sentence1) & set(sentence2))\n",
        "    meanlength = (len(sentence1) + len(sentence2)) / 2\n",
        "    percentage = len(arr_commonwords) / meanlength\n",
        "    ##一致率*係数=点数\n",
        "    #point = int(percentage * coef)\n",
        "    ##一致率>閾値=点数\n",
        "    if percentage >= thres:\n",
        "      point = coef\n",
        "    else:\n",
        "      point = 0\n",
        "\n",
        "    return point, percentage\n",
        "\n",
        "  for s1 in range(matsize-1):\n",
        "    sentence_words1 = extract_words(sentences[s1])\n",
        "    for s2 in range(s1+1, matsize):\n",
        "      sentence_words2 = extract_words(sentences[s2])\n",
        "      point, percentage = compare_sentences(sentence_words1, sentence_words2)\n",
        "      per_mat[s1,s2] = percentage\n",
        "      per_mat[s2,s1] = percentage\n",
        "\n",
        "      if point > 0:\n",
        "        print(s1+1, \"文目と\", s2+1, \"文目の一致率: \", percentage)\n",
        "        points_mat[s1,s2] = point\n",
        "        points_mat[s2,s1] = point\n",
        "  print(points_mat)\n",
        "  print(per_mat)\n",
        "  return points_mat\n",
        "\n",
        "Commonword_addmat(parse_Parag_to_Word(\"グラフを見ると、バッファサイズが非常に小さいときファイルサイズが大きいと非常に時間がかかっている。またread/writeの方がrecv/sendより僅かの差だが、多くの時間を要している。そして、バッファサイズを大きくしていっても、read/writeがrecv/sendより速くなることはなかった。この要因は、ファイルの通信処理はソケットを用いて通信した方が速くなるからであると考える。\"), 4, df_exeptwords, 7, 0.5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0 0 0 0]\n",
            " [0 0 0 0]\n",
            " [0 0 0 0]\n",
            " [0 0 0 0]]\n",
            "[[0.         0.0952381  0.18181818 0.        ]\n",
            " [0.0952381  0.         0.47619048 0.11111111]\n",
            " [0.18181818 0.47619048 0.         0.10526316]\n",
            " [0.         0.11111111 0.10526316 0.        ]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, 0],\n",
              "       [0, 0, 0, 0],\n",
              "       [0, 0, 0, 0],\n",
              "       [0, 0, 0, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-yRTk593UyS",
        "colab_type": "text"
      },
      "source": [
        "# main"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_-cos33CQx-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#要素分類\n",
        "##点数\n",
        "path_Content_points = \"gdrive/My Drive/Colab Notebooks/研究/data/data_prot/Rules/Content_points.csv\"\n",
        "df_Content_points = pd.read_csv(path_Content_points)\n",
        "##要素分類モデル\n",
        "path_sentence_attr_model = \"gdrive/My Drive/Colab Notebooks/研究/data/Statement_attributes/model_svc.model\"\n",
        "##w2vモデル\n",
        "path_wv_model = \"gdrive/My Drive/Colab Notebooks/研究/data/word2vec.model\"\n",
        "\n",
        "#接続詞\n",
        "##接続関係と点数\n",
        "path_Conjuction_attr =  \"gdrive/My Drive/Colab Notebooks/研究/data/data_prot/Rules/Conjuction_attr.csv\"\n",
        "path_Conjuction_points =  \"gdrive/My Drive/Colab Notebooks/研究/data/data_prot/Rules/Conjuction_points.csv\"\n",
        "##山本 和英, 齋藤 真実の分類\n",
        "path_Conjuction_attr_yamamoto =  \"gdrive/My Drive/Colab Notebooks/研究/data/data_prot/Yamamoto_Rules/Conjuction_attr.csv\"\n",
        "path_Conjuction_points_yamamoto =  \"gdrive/My Drive/Colab Notebooks/研究/data/data_prot/Yamamoto_Rules/Conjuction_points.csv\"\n",
        "df_conjuction_attr = pd.read_csv(path_Conjuction_attr)\n",
        "df_conjuction_points = pd.read_csv(path_Conjuction_points)\n",
        "\n",
        "#指示代名詞\n",
        "##点数\n",
        "directive_point = 10\n",
        "\n",
        "#キーワード\n",
        "##単語一覧\n",
        "path_Keywords = \"gdrive/My Drive/Colab Notebooks/研究/data/data_prot/Rules/Keywords.csv\"\n",
        "df_keywords = pd.read_csv(path_Keywords)\n",
        "\n",
        "#共通の単語\n",
        "##単語一覧\n",
        "path_Exeptwords = \"gdrive/My Drive/Colab Notebooks/研究/data/data_prot/Rules/Exeptwords.csv\"\n",
        "df_exeptwords = pd.read_csv(path_Exeptwords)\n",
        "##点数\n",
        "commonwords_coef = 6\n",
        "##閾値\n",
        "commonwords_thres = 0.5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cefT5avtsJRg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#生の文章(paragraph)と結論の位置(target)から点数を出す\n",
        "def Point_matrix(paragraph, target):\n",
        "  #文を分かち書き\n",
        "  sentences = parse_Parag_to_Word(paragraph)\n",
        "  len_sentence = len(sentences)\n",
        "  \n",
        "  #文章の頭から指定の文まで抜き出し\n",
        "  if len_sentence >= target:\n",
        "    sentences = sentences[:target]\n",
        "    len_sentence = len(sentences)\n",
        "\n",
        "  #点数の行列\n",
        "  points_mat = np.array([[50]*target for i in range(len_sentence)])\n",
        "\n",
        "  #要素分類\n",
        "  print(\"---------------要素分類------------------------------------------------\")\n",
        "  arr_content = Content_Classification(paragraph)[:-1]\n",
        "  arr_content.append('claim')\n",
        "  #arr_content = [\"ground\", \"ground\", \"ground\", \"claim\", \"claim\", \"claim\", \"claim\", \"claim\", \"ground\", \"claim\"]\n",
        "  content_addmat = Content_addmat(arr_content, target, df_Content_points)\n",
        "  print(arr_content,\"\\n\",content_addmat)\n",
        "  points_mat += content_addmat\n",
        "\n",
        "  #指示代名詞\n",
        "  print(\"---------------指示代名詞------------------------------------------------\")\n",
        "  directive_addmat = Directive_addmat(sentences, target, directive_point)\n",
        "  points_mat += directive_addmat\n",
        "  \n",
        "  #他キーワード\n",
        "  print(\"---------------キーワード------------------------------------------------\")\n",
        "  keyword_addmat = Keyword_addmat(sentences, target, df_keywords)\n",
        "  points_mat += keyword_addmat\n",
        "\n",
        "  #共通の単語\n",
        "  print(\"---------------共通の単語------------------------------------------------\")\n",
        "  commonword_addmat = Commonword_addmat(sentences, target, df_exeptwords, commonwords_coef, commonwords_thres)\n",
        "  points_mat += commonword_addmat\n",
        "\n",
        "  #接続詞の加点行列\n",
        "  print(\"---------------接続詞------------------------------------------------\")\n",
        "  conjuction_addmat = Paragraph_to_Conjuction_addmat(df_conjuction_attr, df_conjuction_points, sentences, arr_content)\n",
        "  conjuction_addmat['matrix'] = conjuction_addmat['matrix'].map(lambda x: x + points_mat)\n",
        "  print(\"---------------------------------------------------------------------\")\n",
        "\n",
        "  return conjuction_addmat"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6FhwysFcLbCE",
        "colab_type": "code",
        "outputId": "84ac7966-1440-4c62-c81b-f482018e5393",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "df_result = Point_matrix(\"グラフを見ると、バッファサイズが非常に小さいときファイルサイズが大きいと非常に時間がかかっている。またread/writeの方がrecv/sendより僅かの差だが、多くの時間を要している。そして、バッファサイズを大きくしていっても、同様にread/writeがrecv/sendより速くなることはなかった。この要因は、ファイルの通信処理はソケットを用いて通信した方が速くなるからであると考える。\",4)\n",
        "\n",
        "for index, row in df_result.iterrows():\n",
        "  print(row['label'],row['matrix'],\"\\n\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "---------------要素分類------------------------------------------------\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "['ground', 'ground', 'ground', 'claim'] \n",
            " [[0 5 4 5]\n",
            " [5 0 5 6]\n",
            " [4 5 0 7]\n",
            " [5 6 7 0]]\n",
            "---------------指示代名詞------------------------------------------------\n",
            "この  in  3 文目\n",
            "[[ 0  0  0  0]\n",
            " [ 0  0  0  0]\n",
            " [ 0  0  0 10]\n",
            " [ 0  0 10  0]]\n",
            "---------------キーワード------------------------------------------------\n",
            "同様  in  2 文目\n",
            "[[ 0  0  0  0]\n",
            " [ 0  0  0  0]\n",
            " [ 0  0  0 10]\n",
            " [ 0  0 10  0]]\n",
            "---------------共通の単語------------------------------------------------\n",
            "[[0 0 0 0]\n",
            " [0 0 0 0]\n",
            " [0 0 0 0]\n",
            " [0 0 0 0]]\n",
            "[[0.         0.0952381  0.17391304 0.        ]\n",
            " [0.0952381  0.         0.45454545 0.11111111]\n",
            " [0.17391304 0.45454545 0.         0.1       ]\n",
            " [0.         0.11111111 0.1        0.        ]]\n",
            "---------------接続詞------------------------------------------------\n",
            "また  is  ['転換', '対比']\n",
            "-40 points [ 0 : 1 ] to [ 1 : 6 ] with \" 転換 \"\n",
            "array([[  0, -40, -40, -40],\n",
            "       [-40,   0,   0,   0],\n",
            "       [-40,   0,   0,   0],\n",
            "       [-40,   0,   0,   0]])\n",
            "10 points [ 0 : 2 ] to [ 2 : 3 ] with \" 対比 \"\n",
            "array([[ 0,  0, 10,  0],\n",
            "       [ 0,  0, 10,  0],\n",
            "       [10, 10,  0,  0],\n",
            "       [ 0,  0,  0,  0]])\n",
            "そして  is  ['解説', '付加']\n",
            "0 points [ 0 : 1 ] to [ 2 : 3 ] with \" 解説 \"\n",
            "20 points [ 2 : 3 ] to [ 1 : 2 ] with \" 解説 \"\n",
            "array([[ 0,  0,  0,  0],\n",
            "       [ 0,  0, 20,  0],\n",
            "       [ 0, 20,  0,  0],\n",
            "       [ 0,  0,  0,  0]])\n",
            "10 points [ 1 : 3 ] to [ 3 : 4 ] with \" 付加 \"\n",
            "array([[ 0,  0,  0,  0],\n",
            "       [ 0,  0,  0, 10],\n",
            "       [ 0,  0,  0, 10],\n",
            "       [ 0, 10, 10,  0]])\n",
            "---------------------------------------------------------------------\n",
            "2文目:「また」が転換\n",
            "3文目:「そして」が解説\n",
            " [[50 15 14 15]\n",
            " [15 50 75 56]\n",
            " [14 75 50 77]\n",
            " [15 56 77 50]] \n",
            "\n",
            "2文目:「また」が対比\n",
            "3文目:「そして」が解説\n",
            " [[50 55 64 55]\n",
            " [55 50 85 56]\n",
            " [64 85 50 77]\n",
            " [55 56 77 50]] \n",
            "\n",
            "2文目:「また」が転換\n",
            "3文目:「そして」が付加\n",
            " [[50 15 14 15]\n",
            " [15 50 55 66]\n",
            " [14 55 50 87]\n",
            " [15 66 87 50]] \n",
            "\n",
            "2文目:「また」が対比\n",
            "3文目:「そして」が付加\n",
            " [[50 55 64 55]\n",
            " [55 50 65 66]\n",
            " [64 65 50 87]\n",
            " [55 66 87 50]] \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DdH2yeZiXe2i",
        "colab_type": "code",
        "outputId": "2c58f706-af69-4b25-d6dc-6837d45ffe24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "df_result = Point_matrix(\"図26、図27より、バッファサイズが大きくなる程実行時間が短くなることがわかる.さらに、それぞれの近似曲線より、バッファサイズをx、実行時間をyとすると、両者の関係はy=a/x(aはある特定の定数)という方程式で近似的に表せることができ、実行時間はバッファサイズに反比例していることがわかる.また図27より、read、writeによる実装よりも、fread、fwriteによる実装の方が実行時間が速いことがわかる.実行時間がバッファサイズに反比例したのは、次のような理由が考えられる.cでは、ファイルの内容がバッファサイズごとに読み取り・書き込みが行われる.その処理の回数はバッファサイズに反比例する.よって読み取り・書き込みの回数が増えることによって実行時間が増えると考えられる.read、writeによる実装よりも、fread、fwriteによる実装の方が実行時間が速いのには、以下のような理由が考えられる.cは、両者とも同じバッファサイズで実行しているが、システムコールread、write関数の呼び出し回数が大きく違う.これによって両者の実行時間の違いが出ていると考えられる.\",10)\n",
        "\n",
        "for index, row in df_result.iterrows():\n",
        "  print(row['label'],row['matrix'],\"\\n\")\n",
        "  print(\"--------------------------------------------------------\\nthreshold 60\")\n",
        "  for i in range(1, len(row['matrix'])):\n",
        "    for j in range(i):\n",
        "      if row['matrix'][i][j] >= 60:\n",
        "        print(j+1, \"→\", i+1)\n",
        "  print(\"--------------------------------------------------------\\nthreshold 55\")\n",
        "  for i in range(1, len(row['matrix'])):\n",
        "    for j in range(i):\n",
        "      if row['matrix'][i][j] >= 55:\n",
        "        print(j+1, \"→\", i+1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "---------------要素分類------------------------------------------------\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "1\n",
            "1\n",
            "1\n",
            "['ground', 'ground', 'ground', 'ground', 'ground', 'ground', 'claim', 'ground', 'ground', 'claim'] \n",
            " [[ 0  5  4  3  2  1  2 -1 -2 -1]\n",
            " [ 5  0  5  4  3  2  3  0 -1  0]\n",
            " [ 4  5  0  5  4  3  4  1  0  1]\n",
            " [ 3  4  5  0  5  4  5  2  1  2]\n",
            " [ 2  3  4  5  0  5  6  3  2  3]\n",
            " [ 1  2  3  4  5  0  7  4  3  4]\n",
            " [ 2  3  4  5  6  7  0  0 -1  3]\n",
            " [-1  0  1  2  3  4  0  0  5  6]\n",
            " [-2 -1  0  1  2  3 -1  5  0  7]\n",
            " [-1  0  1  2  3  4  3  6  7  0]]\n",
            "---------------指示代名詞------------------------------------------------\n",
            "その  in  5 文目\n",
            "これ  in  9 文目\n",
            "[[ 0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0 10  0  0  0  0]\n",
            " [ 0  0  0  0 10  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0 10]\n",
            " [ 0  0  0  0  0  0  0  0 10  0]]\n",
            "---------------キーワード------------------------------------------------\n",
            "さらに  in  1 文目\n",
            "次  in  3 文目\n",
            "以下  in  7 文目\n",
            "[[ 0 10  0  0  0  0  0  0  0  0]\n",
            " [10  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0 10  0  0  0  0  0]\n",
            " [ 0  0  0 10  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0 10  0]\n",
            " [ 0  0  0  0  0  0  0 10  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0]]\n",
            "---------------共通の単語------------------------------------------------\n",
            "3 文目と 8 文目の一致率:  0.75\n",
            "[[0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 6 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 6 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]]\n",
            "[[0.         0.23529412 0.38095238 0.42105263 0.21052632 0.26666667\n",
            "  0.25       0.17391304 0.33333333 0.25      ]\n",
            " [0.23529412 0.         0.11428571 0.3030303  0.12121212 0.20689655\n",
            "  0.13333333 0.10810811 0.21052632 0.2       ]\n",
            " [0.38095238 0.11428571 0.         0.2        0.         0.\n",
            "  0.23529412 0.75       0.24       0.23529412]\n",
            " [0.42105263 0.3030303  0.2        0.         0.22222222 0.42857143\n",
            "  0.26666667 0.45454545 0.26086957 0.26666667]\n",
            " [0.21052632 0.12121212 0.         0.22222222 0.         0.28571429\n",
            "  0.26666667 0.         0.26086957 0.        ]\n",
            " [0.26666667 0.20689655 0.         0.42857143 0.28571429 0.\n",
            "  0.18181818 0.         0.31578947 0.        ]\n",
            " [0.25       0.13333333 0.23529412 0.26666667 0.26666667 0.18181818\n",
            "  0.         0.21052632 0.2        0.33333333]\n",
            " [0.17391304 0.10810811 0.75       0.45454545 0.         0.\n",
            "  0.21052632 0.         0.22222222 0.21052632]\n",
            " [0.33333333 0.21052632 0.24       0.26086957 0.26086957 0.31578947\n",
            "  0.2        0.22222222 0.         0.2       ]\n",
            " [0.25       0.2        0.23529412 0.26666667 0.         0.\n",
            "  0.33333333 0.21052632 0.2        0.        ]]\n",
            "---------------接続詞------------------------------------------------\n",
            "また  is  ['転換', '対比']\n",
            "-40 points [ 0 : 2 ] to [ 2 : 13 ] with \" 転換 \"\n",
            "array([[  0,   0, -40, -40, -40, -40, -40, -40, -40, -40],\n",
            "       [  0,   0, -40, -40, -40, -40, -40, -40, -40, -40],\n",
            "       [-40, -40,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "       [-40, -40,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "       [-40, -40,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "       [-40, -40,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "       [-40, -40,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "       [-40, -40,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "       [-40, -40,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "       [-40, -40,   0,   0,   0,   0,   0,   0,   0,   0]])\n",
            "10 points [ 1 : 3 ] to [ 3 : 4 ] with \" 対比 \"\n",
            "array([[ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
            "       [ 0,  0,  0, 10,  0,  0,  0,  0,  0,  0],\n",
            "       [ 0,  0,  0, 10,  0,  0,  0,  0,  0,  0],\n",
            "       [ 0, 10, 10,  0,  0,  0,  0,  0,  0,  0],\n",
            "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
            "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
            "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
            "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
            "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
            "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0]])\n",
            "よって  is  ['解説']\n",
            "0 points [ 0 : 5 ] to [ 6 : 7 ] with \" 解説 \"\n",
            "20 points [ 6 : 7 ] to [ 5 : 6 ] with \" 解説 \"\n",
            "array([[ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
            "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
            "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
            "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
            "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
            "       [ 0,  0,  0,  0,  0,  0, 20,  0,  0,  0],\n",
            "       [ 0,  0,  0,  0,  0, 20,  0,  0,  0,  0],\n",
            "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
            "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
            "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0]])\n",
            "---------------------------------------------------------------------\n",
            "3文目:「また」が転換\n",
            "7文目:「よって」が解説\n",
            " [[50 65 14 13 12 11 12  9  8  9]\n",
            " [65 50 15 14 13 12 13 10  9 10]\n",
            " [14 15 50 55 54 53 54 57 50 51]\n",
            " [13 14 55 50 65 54 55 52 51 52]\n",
            " [12 13 54 65 50 65 56 53 52 53]\n",
            " [11 12 53 54 65 50 77 54 53 54]\n",
            " [12 13 54 55 56 77 50 50 49 53]\n",
            " [ 9 10 57 52 53 54 50 50 65 56]\n",
            " [ 8  9 50 51 52 53 49 65 50 67]\n",
            " [ 9 10 51 52 53 54 53 56 67 50]] \n",
            "\n",
            "--------------------------------------------------------\n",
            "threshold 60\n",
            "1 → 2\n",
            "4 → 5\n",
            "5 → 6\n",
            "6 → 7\n",
            "8 → 9\n",
            "9 → 10\n",
            "--------------------------------------------------------\n",
            "threshold 55\n",
            "1 → 2\n",
            "3 → 4\n",
            "4 → 5\n",
            "5 → 6\n",
            "4 → 7\n",
            "5 → 7\n",
            "6 → 7\n",
            "3 → 8\n",
            "8 → 9\n",
            "8 → 10\n",
            "9 → 10\n",
            "3文目:「また」が対比\n",
            "7文目:「よって」が解説\n",
            " [[50 65 54 53 52 51 52 49 48 49]\n",
            " [65 50 55 64 53 52 53 50 49 50]\n",
            " [54 55 50 65 54 53 54 57 50 51]\n",
            " [53 64 65 50 65 54 55 52 51 52]\n",
            " [52 53 54 65 50 65 56 53 52 53]\n",
            " [51 52 53 54 65 50 77 54 53 54]\n",
            " [52 53 54 55 56 77 50 50 49 53]\n",
            " [49 50 57 52 53 54 50 50 65 56]\n",
            " [48 49 50 51 52 53 49 65 50 67]\n",
            " [49 50 51 52 53 54 53 56 67 50]] \n",
            "\n",
            "--------------------------------------------------------\n",
            "threshold 60\n",
            "1 → 2\n",
            "2 → 4\n",
            "3 → 4\n",
            "4 → 5\n",
            "5 → 6\n",
            "6 → 7\n",
            "8 → 9\n",
            "9 → 10\n",
            "--------------------------------------------------------\n",
            "threshold 55\n",
            "1 → 2\n",
            "2 → 3\n",
            "2 → 4\n",
            "3 → 4\n",
            "4 → 5\n",
            "5 → 6\n",
            "4 → 7\n",
            "5 → 7\n",
            "6 → 7\n",
            "3 → 8\n",
            "8 → 9\n",
            "8 → 10\n",
            "9 → 10\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}