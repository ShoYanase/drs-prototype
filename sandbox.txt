図26、図27より、バッファサイズが大きくなる程実行時間が短くなることがわかる。さらに、それぞれの近似曲線より、バッファサイズをx、実行時間をyとすると、両者の関係はy=a/x(aはある特定の定数)という方程式で近似的に表せることができ、実行時間はバッファサイズに反比例していることがわかる。また図27より、read、writeによる実装よりも、fread、fwriteによる実装の方が実行時間が速いことがわかる。実行時間がバッファサイズに反比例したのは、次のような理由が考えられる。cでは、ファイルの内容がバッファサイズごとに読み取り・書き込みが行われる。その処理の回数はバッファサイズに反比例する。よって読み取り・書き込みの回数が増えることによって実行時間が増えると考えられる。read、writeによる実装よりも、fread、fwriteによる実装の方が実行時間が速いのには、以下のような理由が考えられる。cは、両者とも同じバッファサイズで実行しているが、システムコールread、write関数の呼び出し回数が大きく違う。これによって両者の実行時間の違いが出ていると考えられる。

本実験の検証から各プログラムの性能差の原因について仮説を立てる。 仮説としては「バッファサイズが小さい(実行結果ではバッファサイズが500前後)場合ファイルコピー性能はfread, fwriteプログラムの方がread, writeプログラムより高く, 逆にバッファサイズが大きい(実行結果ではバッファサイズが600以上)場合ファイルコピー性能はread, writeプログラムの方がfread, fwriteプログラムより高くなっていく」というものが考えられる。  上記の仮説を支持する証拠は二点ある。一点目はグラフ1からわかる通り, read, writeがfread, fwriteに比して変化率が大きく, また実行結果1と実行結果2から見て取れるように, 特定のバッファサイズで前者の計測時間が後者のそれを下回ることが確認できる点である。 したがって, 実行結果から読み取れるread, writeとfread, fwriteの性能差は仮説の通りであると言える。二点目はreadやwriteのようなシステムコールと, freadやfwriteのようなシステムコールを使わないstdio。hのライブラリとの違いによる点である。 システムコールという機能に関しては, 「システムコールは簡単に実行速度を引き上げる秘密の関数というものではない（ただし、処理の高速化に役立つものもある）。基本的には、システムコールを呼び出さない方がプログラムの実行速度は速くなる」(3)とされる通りである。 readやwriteといったシステムコールは単にそのままではバッファリングを行わないため1バイトごとのデータ読み込みや書き込みを連続で行うことになり, 対してfreadやfwriteといった標準ライブラリはそれに定義されたバッファサイズでバッファリングを自動に行う。 以上より, バッファリングを意図的に行わない場合は標準ライブラリの方がシステムコールより高速に処理をすることができる。 しかし, freadとfwriteに定義されたバッファリングによる読み書き一処理分のバッファサイズ(本実験の実行結果から想定されるサイズは512B)に対し, それを上回るサイズのバッファリングが意図的に行われた場合, 定義されたバッファサイズ毎にファイルコピーを繰り返すという処理が発生するために, 実行時間が増大するのである。したがって, システムコールにおいて適切にバッファリングを行った結果得られたバッファサイズが, 標準ライブラリで定義されているバッファサイズを上回る状態になるために本実験の実行結果が得られ, それらが仮説を支持する証拠であると考えられる。

まず初めに, リース期間を超えた場合の通信内容について, DHCPサーバから指定されたリースの期間を超えると, クライアントがリースの継続をサーバに要求する通信が行われるという仮説を立てた。 
次に結果の考察をする。 まず図 1.14より, クライアントがサーバに対して“DHCP Request”を送信しているのが分かる。 これは, クライアントがリース期間を超える前に, IPアドレスなどのネットワーク接続情報を更新する要求であると考えられる。 これに対し, サーバがクライアントに対し”DHCP NAK”を送信していることが分かる。 ここで, 図 1.15より, リース期間が残り1秒になっていることがわかる。 したがって, リース期間を超えての貸し出しを拒否する通信を行っているといえる。 また, 図 1.13データ部3行目から, ネットワーク情報を再取得し, 接続していることが分かる。 
また, 図 1.16において, LeaseTimeが3600sとなっていることから, 情報の再取得時には, リース期間も再度割り当てられることが分かる。 
したがって, リース期間を超えてのクライアントへのリースはサーバが拒否するため行われず, その代わりにクライアントへ新たに情報を割り当てる通信を行っていると考えられる。 以上から, リース期間を超えて通信した場合について作成したDHCPフローのシーケンス図を図 1.22に示す。

　図7のグラフから,いずれの関数を用いた処理でもバッファサイズを大きくすると,その処理速度が向上する傾向にあるということが分かった。また,システムコールであるread(),write()はバッファサイズが小さいと,C言語の標準関数であるfread(),fwrite()よりも処理に時間がかかることが分かった。更に,バッファサイズを増加させていくと,read(),write()による処理の方が安定し,かつ,fread(),fwrite()よりも多少速いことが確認できた。以下,このような結果となった要因を考察して行く。 バッファサイズを大きくしてゆくと,read(),write()やfread(),fwrite()が一度に読み込むことのできるデータのバイト数が大きくなるため,ストリームに流されたデータを読み込むためにそれらの処理を呼び出す回数が少なくなると考えられる。また,青木峰郎によれば,「read()はバッファを経由した、固定バイト数の入力しかできません。そこでstdioは、まず独自のバッファ(buffer)を用意します」としている1。また,「stdioの1バイト単位APIならば、速度を落とさずに小さい単位で読み込むことができるのです」としている2。fread(),fwrite()による処理の方が,バッファサイズが小さいとき,システムコールよりも速いことの要因としてstdioの用意する独自のバッファが挙げられる。fread()やfwrite()などの標準関数はその実行に当たっては,システムコールであるread()やwrite()を実行している3,何故なら,入出力などのハードウェアとのやり取りをするにはカーネルを仲介する必要があり,これをコマンドの形でまとめたのがシステムコールだからである。このことから,fread()やfwrite()はstdioが用意するバッファを経由して入力または出力するデータをやり取りするバッファリングを行っているため,これ等の関数を何度も呼び出すのではなく,要求された分のデータのみを渡すことで,バッファサイズが小さい段階でシステムコールよりも速く動作すると考えられる。バッファサイズの増加に伴い,read()やwrite()方が標準関数よりも多少速く動作するようになるのは,前述の通り,fread()やfwrite()はバッファを経由し,また,内部ではシステムコールを読んでいるため,read(),write()を単体で用いた場合よりも,実行する手順が多く,また,バッファサイズの増加により,stdioの用意するバッファが無くとも,処理速度に違いがなくなっていくことに起因していると考えられる。しかしながら,ここで新たな疑問が生じる。果たして,このままバッファサイズを大きくし続けた場合,その処理速度はどのように変化していくのか,ということである。必須課題1の実験では,バッファサイズは1024から101376バイトまで変化させている。このバッファサイズをさらに大きくして,それぞれのプログラムの処理速度を計測した。計測結果のグラフを以下の図8に示す。なお,分かりやすさのために,外れ値と考えられる値は考慮せず,また,表示する処理時間の幅を狭くしている。 